{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment3_Q1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visheshagrawal/Course-DeepLearning/blob/main/DL_Assignment3_Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXStuXPz81YF"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8EcxusE7j2z"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from datetime import datetime \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import copy\n",
        "# check device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# DEVICE='cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3zebahRC_hJ",
        "outputId": "b486e1dc-6b43-417a-fe7c-76a043dc4dd8"
      },
      "source": [
        "!pip install torchsummary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSI9Qp7F8a0r"
      },
      "source": [
        "DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c6zYX3lqPlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064b42e7-5aa8-4d9b-e448-ac613940ff47"
      },
      "source": [
        "import pickle\n",
        "#file = open('/content/drive/My Drive/DL_Assignment_3_4/Assignment_3/Question_1/train.pkl', 'rb')\n",
        "# file = open('/content/drive/My Drive/DeepLearning/A3_1/train.pkl', 'rb')\n",
        "file = open('train.pkl', 'rb')\n",
        "data = pickle.load(file)\n",
        "file.close()\n",
        "print('Showing the pickled data:')\n",
        "cnt = 0\n",
        "for item in data:\n",
        "    print('The data ', cnt, ' is : ', item)\n",
        "    cnt += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Showing the pickled data:\n",
            "The data  0  is :  names\n",
            "The data  1  is :  images\n",
            "The data  2  is :  labels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO6PdvpTUFGh",
        "outputId": "c004088d-0c9a-4032-aaae-a8cf4cff3094"
      },
      "source": [
        "file = open('test.pkl', 'rb')\n",
        "data = pickle.load(file)\n",
        "file.close()\n",
        "print('Showing the pickled data:')\n",
        "cnt = 0\n",
        "for item in data:\n",
        "    print('The data ', cnt, ' is : ', item)\n",
        "    cnt += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Showing the pickled data:\n",
            "The data  0  is :  names\n",
            "The data  1  is :  images\n",
            "The data  2  is :  labels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKxbsASHPgUT",
        "outputId": "5e9e10ae-59a5-4d2e-ddab-fbb432324934"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj8F9hmLPn8K"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DeepLearning/A3_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbGGZOm03hcM"
      },
      "source": [
        "image_np_array=[]\n",
        "for item in data[\"images\"]:\n",
        "  # img=np.array(item)\n",
        "  t1=transforms.ToTensor()\n",
        "  img=t1(item)\n",
        "  # img = np.moveaxis(img, -1, 0)\n",
        "  image_np_array.append(img)\n",
        "# image_np_array[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3yIAru3UI_A"
      },
      "source": [
        "test_image_np_array=[]\n",
        "for item in data[\"images\"]:\n",
        "  t1=transforms.ToTensor()\n",
        "  img=t1(item)\n",
        "  test_image_np_array.append(img)\n",
        "\n",
        "test_label_np_array=[]\n",
        "for item in data[\"labels\"]:\n",
        "  label=np.array(item)\n",
        "  test_label_np_array.append(label)\n",
        "\n",
        "test_label_np_array=np.array(test_label_np_array)\n",
        "\n",
        "test_tensor_x=torch.stack(test_image_np_array)\n",
        "test_tensor_y = torch.Tensor(test_label_np_array)\n",
        "\n",
        "my_test_dataset = TensorDataset(test_tensor_x,test_tensor_y) \n",
        "train_size = int(0.85 * len(my_test_dataset))\n",
        "test_size = int(len(my_test_dataset) - train_size)\n",
        "\n",
        "# train_dataset, test_dataset = torch.utils.data.random_split(my_dataset, [train_size, test_size])\n",
        "\n",
        "test_loader = DataLoader(my_test_dataset,batch_size=64,shuffle=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXLGu8wLUSnP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9bCOnQOWdEy",
        "outputId": "1610c746-eb01-4c3f-cf39-f0fcff4a6ce2"
      },
      "source": [
        "image_np_array[0]\n",
        "\n",
        "torch.stack(image_np_array).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYbOXSb563Gt"
      },
      "source": [
        "label_np_array=[]\n",
        "for item in data[\"labels\"]:\n",
        "  label=np.array(item)\n",
        "  label_np_array.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtt_X3JC5cV7"
      },
      "source": [
        "# image_np_array=np.array(image_np_array)\n",
        "label_np_array=np.array(label_np_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKaX-FYxW6Gv",
        "outputId": "2cd5f7d3-8c1a-42a2-962b-c7f50a481474"
      },
      "source": [
        "np.bincount(label_np_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([500, 500, 500, 500, 500, 500, 500, 500, 500, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVuqMEh66bti"
      },
      "source": [
        "# tensor_x = torch.Tensor(image_np_array) # transform to torch tensor\n",
        "\n",
        "tensor_x=torch.stack(image_np_array)\n",
        "tensor_y = torch.Tensor(label_np_array)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "train_size = int(0.85 * len(my_dataset))\n",
        "# val_size = int(0.5*(len(my_dataset) - train_size)\n",
        "test_size = int(len(my_dataset) - train_size)\n",
        "# val_size = len(my_dataset) - train_size - test_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(my_dataset, [train_size, test_size])\n",
        "# val_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [val_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qd_v52Fe2Xa",
        "outputId": "6cb00920-61dc-46d5-d4a2-c4629093e0c4"
      },
      "source": [
        "train_dataset[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlekfbgfVFMJ"
      },
      "source": [
        "# create your dataloader\n",
        "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "valid_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRnSGntjJZPJ"
      },
      "source": [
        "torch.save(train_loader, 'trainloader.pth')\n",
        "torch.save(valid_loader, 'validloader.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab6t3TxkJnm_"
      },
      "source": [
        "new_train_loader=torch.load('trainloader.pth')\n",
        "new_valid_loader=torch.load('validloader.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "lKrpjPh2Jy3K",
        "outputId": "34a2efcb-26cc-44f0-d03c-fdd8a1f59ab9"
      },
      "source": [
        "new_train_loader.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-482a3294d0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_train_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyau1m_4-_Hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eecc4a4-c581-48d0-ab85-30977bb0c68e"
      },
      "source": [
        "for item in iter(train_loader):\n",
        "  print(item[0])\n",
        "  print(item[1])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.4196, 0.3333, 0.3725,  ..., 0.3137, 0.3020, 0.2941],\n",
            "          [0.4353, 0.3373, 0.4745,  ..., 0.3020, 0.2902, 0.3020],\n",
            "          [0.4588, 0.3451, 0.4157,  ..., 0.3294, 0.2941, 0.3098],\n",
            "          ...,\n",
            "          [0.4196, 0.4118, 0.4431,  ..., 0.4314, 0.4392, 0.4706],\n",
            "          [0.4235, 0.4196, 0.4392,  ..., 0.4118, 0.4196, 0.4196],\n",
            "          [0.4196, 0.4235, 0.4667,  ..., 0.4235, 0.4314, 0.4235]],\n",
            "\n",
            "         [[0.3569, 0.2941, 0.3451,  ..., 0.3176, 0.3059, 0.2980],\n",
            "          [0.3725, 0.3020, 0.4471,  ..., 0.2941, 0.2863, 0.2980],\n",
            "          [0.3961, 0.3098, 0.3922,  ..., 0.3176, 0.2824, 0.2980],\n",
            "          ...,\n",
            "          [0.3961, 0.3882, 0.4196,  ..., 0.4196, 0.4275, 0.4588],\n",
            "          [0.3961, 0.3922, 0.4118,  ..., 0.4000, 0.4118, 0.4078],\n",
            "          [0.3804, 0.3843, 0.4314,  ..., 0.3922, 0.4078, 0.3961]],\n",
            "\n",
            "         [[0.1843, 0.1176, 0.1686,  ..., 0.1255, 0.1137, 0.1059],\n",
            "          [0.2039, 0.1255, 0.2667,  ..., 0.1059, 0.0980, 0.1059],\n",
            "          [0.2235, 0.1294, 0.2078,  ..., 0.1333, 0.0980, 0.1098],\n",
            "          ...,\n",
            "          [0.1647, 0.1569, 0.1882,  ..., 0.2039, 0.1882, 0.2275],\n",
            "          [0.1490, 0.1451, 0.1647,  ..., 0.2314, 0.2235, 0.2275],\n",
            "          [0.1412, 0.1451, 0.1922,  ..., 0.2431, 0.2314, 0.2275]]],\n",
            "\n",
            "\n",
            "        [[[0.5059, 0.4824, 0.4706,  ..., 0.3765, 0.3765, 0.3725],\n",
            "          [0.4863, 0.4902, 0.4627,  ..., 0.3804, 0.3765, 0.3725],\n",
            "          [0.4863, 0.4745, 0.5020,  ..., 0.3843, 0.3804, 0.3765],\n",
            "          ...,\n",
            "          [0.6863, 0.5922, 0.6549,  ..., 0.5294, 0.5569, 0.5647],\n",
            "          [0.6588, 0.6471, 0.6627,  ..., 0.5529, 0.5725, 0.5451],\n",
            "          [0.6431, 0.6275, 0.6157,  ..., 0.5412, 0.5333, 0.5255]],\n",
            "\n",
            "         [[0.5020, 0.4902, 0.5255,  ..., 0.5098, 0.5098, 0.5059],\n",
            "          [0.4863, 0.4941, 0.4824,  ..., 0.5137, 0.5098, 0.5059],\n",
            "          [0.4980, 0.4863, 0.5020,  ..., 0.5176, 0.5137, 0.5098],\n",
            "          ...,\n",
            "          [0.5961, 0.5255, 0.5843,  ..., 0.5608, 0.5843, 0.5882],\n",
            "          [0.5529, 0.5765, 0.5882,  ..., 0.5647, 0.5686, 0.5647],\n",
            "          [0.5176, 0.5216, 0.5216,  ..., 0.5725, 0.5725, 0.5647]],\n",
            "\n",
            "         [[0.4275, 0.4078, 0.6824,  ..., 0.8941, 0.8941, 0.8902],\n",
            "          [0.4863, 0.4588, 0.4745,  ..., 0.8941, 0.8902, 0.8863],\n",
            "          [0.5451, 0.4196, 0.3647,  ..., 0.8980, 0.8941, 0.8902],\n",
            "          ...,\n",
            "          [0.5529, 0.5020, 0.5176,  ..., 0.2627, 0.2863, 0.2824],\n",
            "          [0.4588, 0.5020, 0.5059,  ..., 0.2667, 0.2784, 0.2745],\n",
            "          [0.2549, 0.2667, 0.2745,  ..., 0.2588, 0.2706, 0.2667]]],\n",
            "\n",
            "\n",
            "        [[[0.2000, 0.1922, 0.1882,  ..., 0.2039, 0.2039, 0.2078],\n",
            "          [0.2078, 0.2039, 0.2078,  ..., 0.2118, 0.2196, 0.2235],\n",
            "          [0.2431, 0.2196, 0.2235,  ..., 0.2314, 0.2431, 0.2510],\n",
            "          ...,\n",
            "          [0.3843, 0.3686, 0.3216,  ..., 0.4039, 0.4039, 0.4588],\n",
            "          [0.5216, 0.3882, 0.5961,  ..., 0.3843, 0.2627, 0.3569],\n",
            "          [0.3686, 0.3294, 0.5725,  ..., 0.4706, 0.2863, 0.3020]],\n",
            "\n",
            "         [[0.3059, 0.2941, 0.2902,  ..., 0.2902, 0.2902, 0.2980],\n",
            "          [0.3255, 0.3137, 0.3098,  ..., 0.3098, 0.3137, 0.3216],\n",
            "          [0.3451, 0.3412, 0.3333,  ..., 0.3373, 0.3490, 0.3569],\n",
            "          ...,\n",
            "          [0.2941, 0.2706, 0.2275,  ..., 0.4039, 0.4039, 0.4314],\n",
            "          [0.3843, 0.2745, 0.4196,  ..., 0.3882, 0.2745, 0.3569],\n",
            "          [0.2824, 0.2549, 0.4157,  ..., 0.4353, 0.2784, 0.3294]],\n",
            "\n",
            "         [[0.6000, 0.5922, 0.5882,  ..., 0.5922, 0.5922, 0.6000],\n",
            "          [0.6039, 0.5961, 0.6039,  ..., 0.6039, 0.6118, 0.6118],\n",
            "          [0.6078, 0.6196, 0.6118,  ..., 0.6118, 0.6275, 0.6235],\n",
            "          ...,\n",
            "          [0.2706, 0.2588, 0.2196,  ..., 0.4235, 0.4235, 0.4353],\n",
            "          [0.3686, 0.2549, 0.3961,  ..., 0.4039, 0.3176, 0.3647],\n",
            "          [0.2941, 0.2627, 0.3961,  ..., 0.4275, 0.3020, 0.2824]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.1804, 0.1843, 0.1961,  ..., 0.1647, 0.1490, 0.1647],\n",
            "          [0.2039, 0.1961, 0.1882,  ..., 0.1725, 0.1490, 0.1333],\n",
            "          [0.2118, 0.2078, 0.1765,  ..., 0.1922, 0.1961, 0.1843],\n",
            "          ...,\n",
            "          [0.0941, 0.0784, 0.1059,  ..., 0.3686, 0.3059, 0.2039],\n",
            "          [0.0980, 0.0784, 0.0902,  ..., 0.2510, 0.2863, 0.2157],\n",
            "          [0.0902, 0.0824, 0.1137,  ..., 0.2353, 0.2353, 0.1608]],\n",
            "\n",
            "         [[0.3216, 0.2549, 0.2157,  ..., 0.2627, 0.2431, 0.2588],\n",
            "          [0.3255, 0.2706, 0.2353,  ..., 0.2706, 0.2431, 0.2235],\n",
            "          [0.3176, 0.2863, 0.2510,  ..., 0.2863, 0.2902, 0.2784],\n",
            "          ...,\n",
            "          [0.2039, 0.2196, 0.2784,  ..., 0.3882, 0.3451, 0.2902],\n",
            "          [0.1765, 0.1922, 0.2431,  ..., 0.3059, 0.3569, 0.3137],\n",
            "          [0.1529, 0.1765, 0.2471,  ..., 0.3216, 0.3255, 0.2627]],\n",
            "\n",
            "         [[0.1333, 0.1255, 0.1176,  ..., 0.1412, 0.1333, 0.1608],\n",
            "          [0.1608, 0.1412, 0.1137,  ..., 0.1608, 0.1412, 0.1294],\n",
            "          [0.1804, 0.1569, 0.1137,  ..., 0.1843, 0.1922, 0.1765],\n",
            "          ...,\n",
            "          [0.0824, 0.0471, 0.0510,  ..., 0.2667, 0.2510, 0.1804],\n",
            "          [0.0863, 0.0510, 0.0392,  ..., 0.1686, 0.2549, 0.2078],\n",
            "          [0.0824, 0.0549, 0.0667,  ..., 0.1647, 0.2118, 0.1569]]],\n",
            "\n",
            "\n",
            "        [[[0.0078, 0.0118, 0.0431,  ..., 0.0078, 0.0078, 0.0078],\n",
            "          [0.0235, 0.0471, 0.0275,  ..., 0.0118, 0.0118, 0.0118],\n",
            "          [0.0392, 0.0627, 0.0471,  ..., 0.0078, 0.0039, 0.0039],\n",
            "          ...,\n",
            "          [0.0196, 0.0118, 0.0118,  ..., 0.0118, 0.0157, 0.0235],\n",
            "          [0.0392, 0.0314, 0.0196,  ..., 0.0039, 0.0039, 0.0078],\n",
            "          [0.0314, 0.0510, 0.0471,  ..., 0.0039, 0.0039, 0.0078]],\n",
            "\n",
            "         [[0.2863, 0.2863, 0.2588,  ..., 0.2392, 0.2314, 0.2235],\n",
            "          [0.2980, 0.2824, 0.1804,  ..., 0.2510, 0.2392, 0.2353],\n",
            "          [0.3098, 0.2745, 0.1608,  ..., 0.2549, 0.2392, 0.2392],\n",
            "          ...,\n",
            "          [0.3255, 0.3176, 0.3098,  ..., 0.2392, 0.2196, 0.1961],\n",
            "          [0.3098, 0.3098, 0.3020,  ..., 0.2353, 0.2196, 0.2078],\n",
            "          [0.1725, 0.2078, 0.2314,  ..., 0.2314, 0.2196, 0.2157]],\n",
            "\n",
            "         [[0.4588, 0.4510, 0.4078,  ..., 0.3882, 0.3843, 0.3804],\n",
            "          [0.4627, 0.4275, 0.3020,  ..., 0.3961, 0.3882, 0.3843],\n",
            "          [0.4706, 0.4039, 0.2588,  ..., 0.3961, 0.3843, 0.3843],\n",
            "          ...,\n",
            "          [0.5020, 0.4902, 0.4784,  ..., 0.3882, 0.3725, 0.3412],\n",
            "          [0.4863, 0.4863, 0.4824,  ..., 0.3765, 0.3569, 0.3451],\n",
            "          [0.3059, 0.3451, 0.3725,  ..., 0.3765, 0.3569, 0.3529]]],\n",
            "\n",
            "\n",
            "        [[[0.5412, 0.5294, 0.5255,  ..., 0.5569, 0.5608, 0.5569],\n",
            "          [0.5490, 0.5451, 0.5647,  ..., 0.5804, 0.5765, 0.5725],\n",
            "          [0.5412, 0.5255, 0.5255,  ..., 0.5843, 0.5725, 0.5647],\n",
            "          ...,\n",
            "          [0.4118, 0.2627, 0.1176,  ..., 0.4431, 0.4471, 0.4510],\n",
            "          [0.4078, 0.3725, 0.3176,  ..., 0.4588, 0.4588, 0.4627],\n",
            "          [0.4196, 0.4078, 0.4157,  ..., 0.4549, 0.4588, 0.4627]],\n",
            "\n",
            "         [[0.5765, 0.5725, 0.5686,  ..., 0.5725, 0.5765, 0.5686],\n",
            "          [0.5804, 0.5804, 0.5882,  ..., 0.5882, 0.5804, 0.5765],\n",
            "          [0.5765, 0.5647, 0.5608,  ..., 0.5804, 0.5765, 0.5725],\n",
            "          ...,\n",
            "          [0.4353, 0.2745, 0.1255,  ..., 0.4706, 0.4784, 0.4784],\n",
            "          [0.4314, 0.3961, 0.3412,  ..., 0.4863, 0.4902, 0.4941],\n",
            "          [0.4471, 0.4353, 0.4431,  ..., 0.4863, 0.4902, 0.4941]],\n",
            "\n",
            "         [[0.2824, 0.2784, 0.2784,  ..., 0.3137, 0.3137, 0.3098],\n",
            "          [0.2980, 0.2941, 0.3059,  ..., 0.3294, 0.3255, 0.3176],\n",
            "          [0.3098, 0.2980, 0.2902,  ..., 0.3333, 0.3255, 0.3216],\n",
            "          ...,\n",
            "          [0.4078, 0.2549, 0.1137,  ..., 0.4275, 0.4314, 0.4392],\n",
            "          [0.4039, 0.3647, 0.3176,  ..., 0.4392, 0.4392, 0.4510],\n",
            "          [0.4157, 0.4039, 0.4118,  ..., 0.4392, 0.4471, 0.4510]]]])\n",
            "tensor([7., 4., 5., 0., 5., 5., 3., 6., 1., 6., 7., 7., 3., 3., 6., 0., 4., 5.,\n",
            "        2., 3., 4., 7., 9., 9., 6., 3., 3., 6., 6., 2., 4., 7., 4., 7., 4., 5.,\n",
            "        1., 1., 7., 7., 4., 4., 0., 5., 4., 1., 6., 8., 7., 0., 4., 7., 6., 0.,\n",
            "        3., 2., 2., 1., 0., 5., 1., 1., 0., 7.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXRL-i448-qK"
      },
      "source": [
        "TRAINING PART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXMNte_7yHV"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "LEARNING_RATE = 1e-4\n",
        "BATCH_SIZE = 32\n",
        "N_EPOCHS = 50\n",
        "\n",
        "IMG_SIZE = 32\n",
        "N_CLASSES = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsvprR2j74HC"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    '''\n",
        "    Function for the training step of the training loop\n",
        "    '''\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X = X.to(device)\n",
        "        #y_true=torch.LongTensor(y_true)\n",
        "        y_true = y_true.to(device)\n",
        "        y_true=y_true.long()\n",
        "    \n",
        "        # Forward pass\n",
        "        y_hat, _ = model(X) \n",
        "        #y_hat=torch.LongTensor(y_hat)\n",
        "        # y_hat = y_hat.type(torch.LongTensor)\n",
        "        \n",
        "        loss = criterion(y_hat, y_true) \n",
        "        # l1 = 0\n",
        "        # lambda_l1=0.001\n",
        "        # for p in model.parameters():\n",
        "        #   l1 = l1 + p.abs().sum()\n",
        "        # loss = loss + lambda_l1 * l1\n",
        "        # # loss.backward()\n",
        "        # optimizer.step()\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRCgEF_jNbvx"
      },
      "source": [
        "# loss=0\n",
        "# for item in iter(train_loader):\n",
        "#   x_train=item[0]\n",
        "#   y_true=item[1]\n",
        "#   #y_true=torch.Tensor(y_true)\n",
        "#   y_true=y_true.long()\n",
        "#   y_pred=model(x_train)\n",
        "#   print(type(y_true))\n",
        "#   print(type(y_pred[0]))\n",
        "#   loss+=criterion(y_pred[0],y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iZPbGC377hI"
      },
      "source": [
        "def validate(valid_loader, model, criterion, device):\n",
        "    '''\n",
        "    Function for the validation step of the training loop\n",
        "    '''\n",
        "   \n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in valid_loader:\n",
        "    \n",
        "        X = X.to(device)\n",
        "        #y_true=torch.LongTensor(y_true)\n",
        "        \n",
        "        y_true = y_true.to(device)\n",
        "        y_true=y_true.long()\n",
        "\n",
        "\n",
        "        # Forward pass and record loss\n",
        "        y_hat, _ = model(X) \n",
        "        #y_hat = y_hat.type(torch.LongTensor)\n",
        "        # y_hat=torch.LongTensor(y_hat)\n",
        "        loss = criterion(y_hat, y_true) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
        "        \n",
        "    return model, epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0JaY4A579-L"
      },
      "source": [
        "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, device, print_every=1):\n",
        "    '''\n",
        "    Function defining the entire training loop\n",
        "    '''\n",
        "    \n",
        "    # set objects for storing metrics\n",
        "    best_loss = 1e10\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        " \n",
        "    # Train model\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # training\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            model, valid_loss = validate(valid_loader, model, criterion, device)\n",
        "            valid_losses.append(valid_loss)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            \n",
        "            train_acc = get_accuracy(model, train_loader, device=device)\n",
        "            valid_acc = get_accuracy(model, valid_loader, device=device)\n",
        "                \n",
        "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "                  f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.4f}\\t'\n",
        "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
        "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
        "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
        "\n",
        "    plot_losses(train_losses, valid_losses)\n",
        "    \n",
        "    return model, optimizer, (train_losses, valid_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl5QG-hWP9U8"
      },
      "source": [
        "import pickle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylSYPeB7h-oa"
      },
      "source": [
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "activation={}\n",
        "\n",
        "new_model=copy.deepcopy(model)\n",
        "kernels_list=[new_model.block_1[0],new_model.block_1[3],new_model.block_2[0],new_model.block_2[3],new_model.block_3[0],new_model.block_3[3]]\n",
        "name_list=['conv11','conv12','conv21','conv22','conv31','conv32']\n",
        "\n",
        "fig,axis=plt.subplots(1,6,figsize=(15,15))\n",
        "\n",
        "for i in range(len(kernels_list)):\n",
        "  item=kernels_list[i]\n",
        "  # new_model=copy.deepcopy(model) \n",
        "  # new_model.block_1[0].register_forward_hook(get_activation('ext_conv1'))\n",
        "  name=name_list[i]\n",
        "  item.register_forward_hook(get_activation(name))\n",
        "\n",
        "\n",
        "  for j in iter(train_loader):\n",
        "    out=new_model(j[0])\n",
        "    # print(out)\n",
        "    act = activation[name]\n",
        "    # print(act.shape)\n",
        "    break \n",
        "\n",
        "  # act=act[0]\n",
        "  act=torch.mean(act[0],axis=0)\n",
        "  axis[i].imshow(act,cmap=\"gray\")\n",
        "\n",
        "  # num_plot = 16\n",
        "  # fig, axarr = plt.subplots(1,min(act.size(0), num_plot),figsize=(15,15))\n",
        "  # for idx in range(min(act.size(0), num_plot)):\n",
        "  #     axarr[idx].imshow(act[0][idx])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "hcwwNtlZqdAv",
        "outputId": "e5c36530-3e8f-4632-eaad-bd4a2666585a"
      },
      "source": [
        "new_model=copy.deepcopy(model)\n",
        "import cv2\n",
        "\n",
        "\n",
        "# print('Grayscale image shape:', img_gray.shape)\n",
        "kernels_list=[new_model.block_1[0].weight.detach().clone(),new_model.block_1[3].weight.detach().clone(),new_model.block_2[0].weight.detach().clone(),new_model.block_2[3].weight.detach().clone(),new_model.block_3[0].weight.detach().clone(),new_model.block_3[3].weight.detach().clone()]\n",
        "\n",
        "var=6\n",
        "fig,axis=plt.subplots(1,var,figsize=(10,10))  \n",
        "i=0\n",
        "for kernel in kernels_list:\n",
        "  # kernels = new_model.block_1[3].weight.detach().clone()\n",
        "  # kernels.shape\n",
        "  # kernels=kernels[0]\n",
        "  # kernels = kernels - kernels.min()\n",
        "  # kernels = kernels / kernels.max()\n",
        "\n",
        "  kernels = torch.mean(kernel[0], axis=0)\n",
        "\n",
        "  axis[i].imshow(kernels,cmap=\"gray\")\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3VGnQ77u51E"
      },
      "source": [
        "# Visualise 10 random images from each class\n",
        "array=[[0 for j in range(10)] for i in range(10)]\n",
        "for j in range(10):\n",
        "  count=0\n",
        "  for test_images, test_labels in train_loader:\n",
        "    for k in range(64):\n",
        "      if count>=10:\n",
        "        break  \n",
        "      elif test_labels[k].item()==j:\n",
        "        print(test_labels[k].item())\n",
        "        print(j)\n",
        "        count+=1\n",
        "        array[j][count-1]=test_images[k]\n",
        "    # sample_image = test_images[0]    # Reshape them according to your needs.\n",
        "    # sample_label = test_labels[0]\n",
        "    # print(sample_image)\n",
        "    # print(sample_label)\n",
        "    # break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "BZ2U-ZA17olC",
        "outputId": "27887a41-058f-47fd-8a8f-7e76822cb948"
      },
      "source": [
        "for i in range(len(array)):\n",
        "  for j in range(len(array[0])):\n",
        "    plt.imshow(array[i][j].permute(1,2,0))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "y1LHLPHx8hU4",
        "outputId": "c1d14303-8b7c-4be1-bfd2-86737e02f9e6"
      },
      "source": [
        "plt.imshow(array[0][2].permute(1,2,0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd7610defd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WdHAq3Z_Uj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "fbc821f1-eac6-4817-8826-99725279ec6b"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DeepLearning/A3_1\")\n",
        "\n",
        "for i in range(len(array)):\n",
        "  for j in range(len(array[0])):\n",
        "    # plt.imshow(array[i][j].permute(1,2,0))\n",
        "    torchvision.utils.save_image(array[i][j],\"img_\"+str(i)+\"_\"+str(j)+\".png\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-ba6523d9e2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DeepLearning/A3_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DeepLearning/A3_1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfyqgLiZz11Z"
      },
      "source": [
        "class CNN_Model_1(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(CNN_Model_1, self).__init__()\n",
        "        \n",
        "        self.block_1 = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(kernel_size = 2),\n",
        "            # nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "            # nn.ReLU(),\n",
        "            # nn.BatchNorm2d(16),\n",
        "            # nn.MaxPool2d(kernel_size=1),\n",
        "            # nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "            # nn.ReLU(),\n",
        "            # nn.BatchNorm2d(16),\n",
        "            # nn.MaxPool2d(kernel_size=1),\n",
        "            # # nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "            # nn.ReLU(),\n",
        "            # nn.BatchNorm2d(16),\n",
        "            # nn.MaxPool2d(kernel_size=1)\n",
        "            # ,\n",
        "            # # nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            # nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=15*15*16, out_features=120),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=120, out_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=32, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=x.view(-1,3,32,32)\n",
        "        x = self.block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # print(x.shape)\n",
        "        logits = self.classifier(x)\n",
        "        prob=nn.Softmax(dim=1)(logits)\n",
        "        pred=nn.LogSoftmax(dim=1)(logits)\n",
        "        return pred, prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXN3QOpsz-9N"
      },
      "source": [
        "class CNN_Model_2(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(CNN_Model_2, self).__init__()\n",
        "        \n",
        "        self.block_1 = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.4),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.4),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=5*5*32, out_features=120),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.4),\n",
        "            nn.Linear(in_features=120, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x=x.view(-1,3,32,32)\n",
        "        x = self.block_1(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x = self.block_2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        prob=nn.Softmax(dim=1)(logits)\n",
        "        pred=nn.LogSoftmax(dim=1)(logits)\n",
        "        return pred, prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3fELOZfz_OM"
      },
      "source": [
        "#Block1+2+3 + FC and softmax\n",
        "class CNN_Model_3(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(CNN_Model_3, self).__init__()\n",
        "        \n",
        "        self.block_1 = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1),\n",
        "            # nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=1),\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        self.block_2=nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            \n",
        "            #nn.BatchNorm2d(32),\n",
        "            # nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.5),\n",
        "        )\n",
        "\n",
        "        self.block_3=nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            # nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            #nn.Dropout(0.4),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            # nn.BatchNorm2d(64),\n",
        "            # nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.5)\n",
        "\n",
        "            # nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            # nn.BatchNorm2d(64),\n",
        "            # nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.8)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=1*1*64, out_features=20),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Linear(in_features=20, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x=x.view(-1,3,32,32)\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        #print(x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        prob=nn.Softmax(dim=1)(logits)\n",
        "        pred=nn.LogSoftmax(dim=1)(logits)\n",
        "        return pred, prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9wxme6dqZK3",
        "outputId": "66a007bd-faa1-4c2f-fdb0-476b03c5e73a"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Model_3(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_3): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=20, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaxHMADd8L3N"
      },
      "source": [
        "def get_accuracy(model, data_loader, device):\n",
        "    '''\n",
        "    Function for computing the accuracy of the predictions over the entire data_loader\n",
        "    '''\n",
        "    \n",
        "    correct_pred = 0 \n",
        "    n = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_true in data_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            _, y_prob = model(X)\n",
        "            _, predicted_labels = torch.max(y_prob, 1)\n",
        "\n",
        "            n += y_true.size(0)\n",
        "            correct_pred += (predicted_labels == y_true).sum()\n",
        "\n",
        "    return correct_pred.float() / n\n",
        "\n",
        "def plot_losses(train_losses, valid_losses):\n",
        "    '''\n",
        "    Function for plotting training and validation losses\n",
        "    '''\n",
        "    \n",
        "    # temporarily change the style of the plots to seaborn \n",
        "    plt.style.use('seaborn')\n",
        "\n",
        "    train_losses = np.array(train_losses) \n",
        "    valid_losses = np.array(valid_losses)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize = (8, 4.5))\n",
        "\n",
        "    ax.plot(train_losses, color='blue', label='Training loss') \n",
        "    ax.plot(valid_losses, color='red', label='Validation loss')\n",
        "    ax.set(title=\"Loss over epochs\", \n",
        "            xlabel='Epoch',\n",
        "            ylabel='Loss') \n",
        "    ax.legend()\n",
        "    fig.show()\n",
        "    \n",
        "    # change the plot style to default\n",
        "    plt.style.use('default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsZjQJYW8N_n"
      },
      "source": [
        "# torch.manual_seed(RANDOM_SEED)\n",
        "# model = CNN_Model(X = 1, Y = 0, Z = 0, n_fc_layers = 1, input_features = [3600], output_features = [N_CLASSES]).to(DEVICE)\n",
        "model = CNN_Model_3(10).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)#,weight_decay=1e-5)\n",
        "criterion = nn.NLLLoss().to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuiYSNLkdNxr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8ZC4JME8S19"
      },
      "source": [
        "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader,135, DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5l5OxWcYiN-"
      },
      "source": [
        "loaded_model, optimizer, _ = training_loop(loaded_model, criterion, optimizer, train_loader, test_loader,135, DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbJMPyIPZKYp",
        "outputId": "0c744b00-03d1-4b20-9369-ab66b64ecc2e"
      },
      "source": [
        "get_accuracy(loaded_model, test_loader, DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7430, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWDYkCIJrk4S"
      },
      "source": [
        "Epoch: 49\tTrain loss: 0.8330\tValid loss: 0.9121\tTrain accuracy: 79.65\tValid accuracy: 70.13\n",
        "Train loss: 0.9573\tValid loss: 0.9451\tTrain accuracy: 76.59\tValid accuracy: 69.73\n",
        "\n",
        "16:52:34 --- Epoch: 134\tTrain loss: 0.6878\tValid loss: 0.8254\tTrain accuracy: 86.87\tValid accuracy: 74.13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN_hJh03Qju8"
      },
      "source": [
        "get_accuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x80Fg7thpqRn"
      },
      "source": [
        "filename = 'best_model_dropout0.3.sav'\n",
        "# pickle.dump(model, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "# result = loaded_model.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiUUBQCUZ590"
      },
      "source": [
        "filename = 'new_best_model_dropout0.3.sav'\n",
        "pickle.dump(loaded_model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I34LJSOdzOUo",
        "outputId": "1a364bbe-252b-48e3-b1a1-aae3ac5579ac"
      },
      "source": [
        "loaded_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Model_3(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_3): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=20, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=20, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42gQEafC8Uq6"
      },
      "source": [
        "ROW_IMG = 10\n",
        "N_ROWS = 5\n",
        "\n",
        "fig = plt.figure()\n",
        "for index in range(1, ROW_IMG * N_ROWS + 1):\n",
        "    plt.subplot(N_ROWS, ROW_IMG, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(valid_dataset.data[index], cmap='gray_r')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        _, probs = model(valid_dataset[index][0].unsqueeze(0).to(DEVICE))\n",
        "        \n",
        "    title = f'{torch.argmax(probs)} ({torch.max(probs * 100):.0f}%)'\n",
        "    \n",
        "    plt.title(title, fontsize=7)\n",
        "fig.suptitle('LeNet-5 - predictions');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWNwlbzSuDC9"
      },
      "source": [
        "#Block1+2+3 + FC and softmax\n",
        "class CNN_Model_3(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(CNN_Model_3, self).__init__()\n",
        "        \n",
        "        self.block_1 = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1),\n",
        "            # nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=1),\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        self.block_2=nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.5),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1),\n",
        "            \n",
        "            #nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        self.block_3=nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            #nn.Dropout(0.4),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            # nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.3)\n",
        "\n",
        "            # nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "            # nn.BatchNorm2d(64),\n",
        "            # nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2),\n",
        "            # nn.Dropout(0.8)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=1*1*64, out_features=20),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(in_features=20, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x=x.view(-1,3,32,32)\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        #print(x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        prob=nn.Softmax(dim=1)(logits)\n",
        "        pred=nn.LogSoftmax(dim=1)(logits)\n",
        "        return pred, prob"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}